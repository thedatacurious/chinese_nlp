{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data from Douban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(x):\n",
    "    # Extract content using class or text\n",
    "    reviews = [i.text.replace('\\n', '') for i in x.find_all('span', {'class':'short'})]\n",
    "    dates = [i.text.replace('\\n', '').strip() for i in x.find_all('span', {'class':'comment-time'})]\n",
    "    ratings = [int(str(i.find_next())[20]) for i in x.find_all(text = '看过')]\n",
    "    votes = [int(i.text) for i in x.find_all('span', {'class':'votes'})]\n",
    "    # Create dictionary to store scraped info\n",
    "    for item in zip(reviews, dates, ratings, votes):\n",
    "        scraped_info = {\n",
    "        'review': item[0],\n",
    "        'created_at': item[1],\n",
    "        'rating': item[2],\n",
    "        'votes': item[3]\n",
    "        }\n",
    "        yield scraped_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lifesaver: https://stackoverflow.com/questions/23102833/how-to-scrape-a-website-which-requires-login-using-python-and-beautifulsoup\n",
    "\n",
    "with open('/home/thedatacurious/credentials.yaml') as file:\n",
    "    cookies = yaml.load(file, Loader=yaml.FullLoader)['douban_cookies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 reviews have been scraped\n",
      "220 reviews have been scraped\n",
      "320 reviews have been scraped\n",
      "420 reviews have been scraped\n"
     ]
    }
   ],
   "source": [
    "content2 = []\n",
    "\n",
    "for page in range(0,500,20):\n",
    "        url = \"https://movie.douban.com/subject/27010768/comments?start={}&limit=20&sort=new_score&status=P&percent_type=l\".format(page)\n",
    "        headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:75.0) Gecko/20100101 Firefox/75.0',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Referer': 'https://accounts.douban.com/passport/login?source=movie',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        }\n",
    "\n",
    "        params = (\n",
    "        ('start', '{}'),\n",
    "        ('amp;limit', '20'),\n",
    "        ('amp;sort', 'new_score'),\n",
    "        ('amp;status', 'P'),\n",
    "        ('amp;percent_type', 'm'),\n",
    "        )\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params, cookies=cookies, timeout = 10)\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        time.sleep(random.randint(2,5))\n",
    "\n",
    "        content2.extend(extract(soup))\n",
    "        \n",
    "        if page !=0 and page % 100 == 0:\n",
    "            print('{} reviews have been scraped'.format(len(content2)))\n",
    "            time.sleep(random.randint(5,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = pd.DataFrame(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium.to_csv('../data/raw/meh_parasite_reviews.csv', index =False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = pd.DataFrame(content2)\n",
    "low.to_csv('../data/raw/poor_parasite_reviews.csv', index =False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = medium.append(low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>created_at</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>与《燃烧》相同，反应了贫富阶级的差异和对立，揭露了底层社会的绝望和无奈；但是与《燃烧》不同的...</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>3</td>\n",
       "      <td>7109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>穷人能言擅骗，个个骗术精湛，有此骗术及演技，还用住在地下室？富人幼稚可欺，全家单纯无脑，被人...</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>3</td>\n",
       "      <td>5189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>我为批评《燃烧》而向李沧东道歉。</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>3</td>\n",
       "      <td>2698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>看的有点难受，不是因为影片残忍，而是——实在太硬凹了。情节上的巧合可以理解，但一个没人找得到...</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>3</td>\n",
       "      <td>2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>无法原谅开门放人进来这个facile的瞬间</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>3</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  created_at  rating  \\\n",
       "0  与《燃烧》相同，反应了贫富阶级的差异和对立，揭露了底层社会的绝望和无奈；但是与《燃烧》不同的...  2019-06-10       3   \n",
       "1  穷人能言擅骗，个个骗术精湛，有此骗术及演技，还用住在地下室？富人幼稚可欺，全家单纯无脑，被人...  2019-08-07       3   \n",
       "2                                   我为批评《燃烧》而向李沧东道歉。  2019-08-07       3   \n",
       "3  看的有点难受，不是因为影片残忍，而是——实在太硬凹了。情节上的巧合可以理解，但一个没人找得到...  2019-08-07       3   \n",
       "4                              无法原谅开门放人进来这个facile的瞬间  2019-05-30       3   \n",
       "\n",
       "   votes  \n",
       "0   7109  \n",
       "1   5189  \n",
       "2   2698  \n",
       "3   2699  \n",
       "4    858  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv('../data/raw/combined_parasite_reviews.csv', index =False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
